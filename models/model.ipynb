{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ec0464",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaedc789",
   "metadata": {},
   "source": [
    "# Amazon Review Sentiment Analysis Model\n",
    "\n",
    "This notebook builds a Keras neural network model for sentiment analysis on Amazon product reviews.\n",
    "\n",
    "**Objective:** Classify reviews as Positive (1) or Negative (0)\n",
    "**Dataset:** Amazon Product Reviews\n",
    "**Features:** Review body text\n",
    "**Output:** Sentiment (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Explore Dataset\n",
    "df = pd.read_csv('Amazon-Product-Reviews - Amazon Product Review (1).csv')\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d856e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# Remove rows with missing review_body or sentiment\n",
    "df = df.dropna(subset=['review_body', 'sentiment'])\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates(subset=['review_body'], keep='first')\n",
    "\n",
    "# Convert sentiment to binary (ensure 0 and 1 values)\n",
    "df['sentiment'] = df['sentiment'].astype(int)\n",
    "\n",
    "print(f\"Dataset size after cleaning: {len(df)}\")\n",
    "print(f\"\\nSentiment distribution after cleaning:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print(df['sentiment'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Feature Extraction using CountVectorizer\n",
    "# This converts text into numerical features\n",
    "\n",
    "# Create separate vectorizers for title and body (as in the project structure)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorizer for review body\n",
    "cv_body = CountVectorizer(max_features=1000, stop_words='english')\n",
    "X_body = cv_body.fit_transform(df['review_body']).toarray()\n",
    "\n",
    "# Vectorizer for review headline\n",
    "cv_title = CountVectorizer(max_features=100, stop_words='english')\n",
    "X_title = cv_title.fit_transform(df['review_headline']).toarray()\n",
    "\n",
    "# Combine features\n",
    "X = np.hstack([X_title, X_body])\n",
    "y = df['sentiment'].values\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Title features: {X_title.shape[1]}\")\n",
    "print(f\"Body features: {X_body.shape[1]}\")\n",
    "print(f\"Total features: {X.shape[1]}\")\n",
    "\n",
    "# Save vectorizers for later use in the app\n",
    "import joblib\n",
    "joblib.dump(cv_title, 'cv1.pkl')\n",
    "joblib.dump(cv_body, 'cv2.pkl')\n",
    "print(\"\\nVectorizers saved: cv1.pkl, cv2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d615849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance Dataset using SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "print(\"Balancing dataset...\")\n",
    "print(f\"Before balancing - Sentiment distribution:\")\n",
    "print(pd.Series(y).value_counts())\n",
    "print(f\"Class ratio: {y.value_counts()[1] / y.value_counts()[0]:.2%}\")\n",
    "\n",
    "# Method 1: SMOTE + Undersampling for optimal balance\n",
    "# SMOTE creates synthetic samples for minority class\n",
    "# Undersampler reduces majority class to balance\n",
    "imb_pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=42, k_neighbors=5)),\n",
    "    ('under', RandomUnderSampler(random_state=42, sampling_strategy=0.8))\n",
    "])\n",
    "\n",
    "X_balanced, y_balanced = imb_pipeline.fit_resample(X, y)\n",
    "\n",
    "print(f\"\\nAfter balancing - Sentiment distribution:\")\n",
    "print(pd.Series(y_balanced).value_counts())\n",
    "print(f\"Class ratio: {y_balanced.value_counts()[1] / y_balanced.value_counts()[0]:.2%}\")\n",
    "print(f\"New dataset size: {len(X_balanced)} (was {len(X)})\")\n",
    "\n",
    "# Use balanced data for training\n",
    "X = X_balanced\n",
    "y = y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921736d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"\\nTraining set sentiment distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nTest set sentiment distribution:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5389d32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Keras Neural Network Model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', \n",
    "             tf.keras.metrics.Precision(),\n",
    "             tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "print(\"Model Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6aa937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=2,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training History\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history visualization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2644df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model on Test Set\n",
    "print(\"Evaluating model on test set...\")\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"{'Model Performance Metrics':<30}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d36fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Trained Model\n",
    "model.save('model.keras')\n",
    "print(\"âœ“ Model saved as 'model.keras'\")\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"- Total parameters: {model.count_params():,}\")\n",
    "print(f\"- Input shape: {model.input_shape}\")\n",
    "print(f\"- Output shape: {model.output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44376b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model with Sample Reviews\n",
    "def predict_sentiment(review_text, title_text=\"\"):\n",
    "    \\\"\\\"\\\"\n",
    "    Predict sentiment for a given review.\n",
    "    \n",
    "    Args:\n",
    "        review_text: The review body text\n",
    "        title_text: The review title text\n",
    "        \n",
    "    Returns:\n",
    "        dict with sentiment label and confidence score\n",
    "    \\\"\\\"\\\"\n",
    "    # Transform using the saved vectorizers\n",
    "    title_features = cv_title.transform([title_text]).toarray()\n",
    "    body_features = cv_body.transform([review_text]).toarray()\n",
    "    features = np.hstack([title_features, body_features])\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(features, verbose=0)[0][0]\n",
    "    sentiment = 'POSITIVE' if prediction > 0.5 else 'NEGATIVE'\n",
    "    confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "    \n",
    "    return {\n",
    "        'sentiment': sentiment,\n",
    "        'confidence': float(confidence),\n",
    "        'raw_score': float(prediction)\n",
    "    }\n",
    "\n",
    "# Test with sample reviews\n",
    "test_reviews = [\n",
    "    (\"This product is amazing!\", \"Great quality\"),\n",
    "    (\"Terrible product, waste of money\", \"Worst purchase\"),\n",
    "    (\"It's okay, nothing special\", \"Average\"),\n",
    "    (\"Love it! Best product ever\", \"Five stars\"),\n",
    "]\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(\"=\" * 70)\n",
    "for review, title in test_reviews:\n",
    "    result = predict_sentiment(review, title)\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Prediction: {result['sentiment']} ({result['confidence']:.2%})\")\n",
    "    print(\"-\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
